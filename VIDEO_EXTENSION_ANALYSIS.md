# üé¨ Video Extension & Character Consistency - ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 15 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏° 2568  
**‡∏ú‡∏π‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:** GitHub Copilot AI Assistant  
**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:** üìã Planning Complete

---

## üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### 1. ‚ö†Ô∏è Progress Bar Non-Monotonic Bug
**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç progress ‡∏Ç‡∏¢‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏î‡∏•‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
```typescript
// replicateService.ts: waitForPrediction()
const elapsed = Date.now() - startTime;
const estimatedTotal = 45000; // 45s average
const progress = Math.min((elapsed / estimatedTotal) * 100, 95);
onProgress(progress);  // ‚ùå ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏≠‡∏≤‡∏à‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏Å‡πà‡∏≤
```

**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:** UX ‡πÅ‡∏¢‡πà ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏±‡∏ö‡∏™‡∏ô

---

### 2. ‚úÖ Image-to-Video (I2V) Support
**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:** ‚úÖ **‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ**

**‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô:**
```typescript
// generateAnimateDiffVideo()
if (image) {
  input.image = `data:image/png;base64,${image}`;  // ‚úÖ ‡∏£‡∏±‡∏ö base64
}

// generateSVDVideo()
input = {
  image: image,  // ‚úÖ REQUIRED for SVD
  num_frames: 14,
  motion_bucket_id: 127
};
```

**‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ:** ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

---

### 3. ‚ö†Ô∏è Video Extension (Sequential Generation)
**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ last frame ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô first frame ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

**‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:**
- ‡πÄ‡∏û‡∏¥‡πà‡∏° `previousVideo` parameter ‡πÉ‡∏ô `generateShotVideo()`
- Extract last frame ‡∏à‡∏≤‡∏Å previous video
- ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô `baseImage` ‡πÉ‡∏´‡πâ I2V models
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Replicate (AnimateDiff, SVD) ‡πÅ‡∏•‡∏∞ ComfyUI

---

### 4. ‚ö†Ô∏è Character Consistency
**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÑ‡∏°‡πà‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏â‡∏≤‡∏Å

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Face ID/LoRA integration ‡πÉ‡∏ô video pipeline

**‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:**
- ‡πÄ‡∏û‡∏¥‡πà‡∏° Face ID support (InstantID/IP-Adapter)
- ‡πÄ‡∏û‡∏¥‡πà‡∏° Character LoRA selection
- Apply LoRA ‡πÉ‡∏ô video generation workflow

---

### 5. ‚ö†Ô∏è Pixel-perfect Continuity
**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ last frame ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô first frame ‡πÅ‡∏ö‡∏ö pixel-perfect

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- Extract last frame ‡∏à‡∏≤‡∏Å video ‡∏î‡πâ‡∏ß‡∏¢ Canvas API (client-side)
- ‡∏´‡∏£‡∏∑‡∏≠ FFmpeg (server-side)
- ‡∏™‡πà‡∏á frame ‡πÄ‡∏õ‡πá‡∏ô init_image ‡πÉ‡∏´‡πâ I2V model
- ‡∏ï‡∏±‡πâ‡∏á `denoise_strength = 0.3-0.5` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤ composition

---

## üéØ ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

### Priority 1: Fix Progress Bar (CRITICAL) üî¥
**‡πÄ‡∏ß‡∏•‡∏≤:** 30 ‡∏ô‡∏≤‡∏ó‡∏µ  
**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:** UX ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```typescript
// replicateService.ts
let lastProgress = 0;  // ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

async function waitForPrediction(...) {
  while (true) {
    if (onProgress) {
      const elapsed = Date.now() - startTime;
      const progress = Math.min((elapsed / estimatedTotal) * 100, 95);
      
      // ‚úÖ Monotonic: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
      if (progress > lastProgress) {
        lastProgress = progress;
        onProgress(lastProgress);
      }
    }
  }
}
```

---

### Priority 2: Add Video Extension API üü°
**‡πÄ‡∏ß‡∏•‡∏≤:** 2 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á  
**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:** Feature ‡πÉ‡∏´‡∏°‡πà ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å

**Interface:**
```typescript
export interface VideoGenerationOptions {
  // ...existing options
  
  // üÜï Video Extension
  previousVideo?: string;  // URL ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
  endFrameInfluence?: number;  // 0-1, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡∏≠‡∏á last frame (default: 0.7)
  transitionType?: 'seamless' | 'smooth' | 'creative';
}

// üÜï Helper: Extract last frame from video
export async function extractLastFrame(videoUrl: string): Promise<string> {
  // Implementation using Canvas API
}

// ‚úÖ Updated generateShotVideo()
export async function generateShotVideo(
  shot: VideoShot,
  baseImage?: string,
  options: VideoGenerationOptions = {},
  onProgress?: (progress: number) => void
): Promise<string> {
  // üÜï Extract last frame if previousVideo provided
  let initImage = baseImage;
  if (options.previousVideo) {
    initImage = await extractLastFrame(options.previousVideo);
  }
  
  // ‡πÉ‡∏ä‡πâ initImage ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥
  const videoUrl = await generateStoryboardVideo(
    prompt,
    initImage,  // ‚úÖ Last frame from previous video
    onProgress,
    ...
  );
}
```

**Helper Function:**
```typescript
/**
 * Extract last frame from video URL
 */
export async function extractLastFrame(videoUrl: string): Promise<string> {
  return new Promise((resolve, reject) => {
    const video = document.createElement('video');
    video.crossOrigin = 'anonymous';
    video.src = videoUrl;
    
    video.onloadedmetadata = () => {
      // Seek to last frame
      video.currentTime = video.duration - 0.1;
    };
    
    video.onseeked = () => {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      
      const ctx = canvas.getContext('2d');
      ctx!.drawImage(video, 0, 0);
      
      // Convert to base64
      const base64 = canvas.toDataURL('image/png').split(',')[1];
      resolve(base64);
    };
    
    video.onerror = reject;
  });
}
```

---

### Priority 3: Character Consistency üü¢
**‡πÄ‡∏ß‡∏•‡∏≤:** 3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á  
**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:** ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**

1. **‡πÄ‡∏û‡∏¥‡πà‡∏° Face Reference Support:**
```typescript
export interface VideoGenerationOptions {
  // ...existing
  
  // üÜï Character Consistency
  characterReference?: {
    faceImage: string;  // Face ID reference
    loraPath?: string;  // Custom LoRA model
    loraStrength?: number;  // 0-1 (default: 0.8)
  };
}
```

2. **Update Workflow:**
```typescript
// geminiService.ts: generateVideoWithComfyUI()
async function generateVideoWithComfyUI(options) {
  // ...
  
  // üÜï Add IP-Adapter for Face ID
  if (options.characterReference?.faceImage) {
    workflow['ip_adapter'] = {
      inputs: {
        model: ['1', 0],
        clip_vision: ['clip_vision_loader', 0],
        image: options.characterReference.faceImage,
        weight: 0.9,
        noise: 0.0
      },
      class_type: 'IPAdapterApply'
    };
  }
  
  // üÜï Add LoRA if provided
  if (options.characterReference?.loraPath) {
    workflow['lora'] = {
      inputs: {
        lora_name: options.characterReference.loraPath,
        strength_model: options.characterReference.loraStrength || 0.8,
        model: ['1', 0]
      },
      class_type: 'LoraLoader'
    };
  }
}
```

---

### Priority 4: Pixel-perfect Continuity üü¢
**‡πÄ‡∏ß‡∏•‡∏≤:** 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á  
**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:** ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```typescript
// ComfyUI: Use lower denoising for better continuity
if (options.previousVideo) {
  workflow['sampler']['inputs']['denoise'] = 0.4;  // ‚úÖ Keep 60% of original
}

// Replicate: Use higher cond_aug for SVD
const svdOptions = {
  cond_aug: 0.01,  // ‚úÖ Less noise = more faithful to input
  motion_bucket_id: 100  // ‚úÖ Moderate motion
};
```

---

## üìù Implementation Checklist

### Phase 1: Fix Progress Bar (30 min) ‚úÖ
- [ ] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `waitForPrediction()` ‡πÉ‡∏´‡πâ monotonic
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö single shot generation
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö batch generation
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ progress ‡∏•‡∏î‡∏•‡∏á

### Phase 2: Video Extension API (2 hours)
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° `previousVideo` parameter ‡πÉ‡∏ô `VideoGenerationOptions`
- [ ] Implement `extractLastFrame()` helper
- [ ] Update `generateShotVideo()` ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö sequential
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° UI controls ‡πÉ‡∏ô Step5Output
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö shot 1 ‚Üí shot 2 ‚Üí shot 3 continuity

### Phase 3: Character Consistency (3 hours)
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° `characterReference` parameter
- [ ] Integrate IP-Adapter workflow
- [ ] Support LoRA selection
- [ ] Update `generateStoryboardVideo()` flow
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô

### Phase 4: Pixel-perfect Continuity (1 hour)
- [ ] Adjust denoise parameters
- [ ] Fine-tune motion strength
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö frame matching quality
- [ ] ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö before/after

---

## üéì Technical Notes

### Video Extension Workflow:
```
Shot 1: Generate normally
  ‚Üì
Extract last frame (Canvas API)
  ‚Üì
Shot 2: Use last frame as init_image
  ‚Üì (denoise = 0.4, preserve 60%)
Generate with continuity
  ‚Üì
Extract last frame again
  ‚Üì
Shot 3: Continue...
```

### Character Consistency Workflow:
```
Character Face Image
  ‚Üì
IP-Adapter (Face Embedding)
  ‚Üì
+ Custom LoRA (if available)
  ‚Üì
Video Generation
  ‚Üì
‚úÖ Consistent Face across all shots
```

---

## üöÄ Expected Results

### After Priority 1 (Progress Fix):
- ‚úÖ Progress bar ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á
- ‚úÖ UX ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏™‡∏±‡∏ö‡∏™‡∏ô

### After Priority 2 (Video Extension):
- ‚úÖ Shot ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏´‡∏•
- ‚úÖ Last frame ‚Üí First frame seamless
- ‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ jump cut ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

### After Priority 3 (Character Consistency):
- ‚úÖ ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏∏‡∏Å‡∏â‡∏≤‡∏Å
- ‚úÖ ‡πÄ‡∏≠‡∏Å‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
- ‚úÖ ‡πÉ‡∏ä‡πâ LoRA ‡πÑ‡∏î‡πâ

### After Priority 4 (Pixel-perfect):
- ‚úÖ Frame ‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏ö pixel-level match
- ‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ flicker ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏â‡∏≤‡∏Å
- ‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

---

**‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏ß‡∏°:** 6.5 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á  
**‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥:** 1 ‚Üí 2 ‚Üí 3 ‚Üí 4

---

*‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏î‡∏¢: GitHub Copilot AI Assistant*  
*‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: ‡∏û‡∏£‡πâ‡∏≠‡∏° Implement*
